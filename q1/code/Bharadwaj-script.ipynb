{"cells":[{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":18356,"status":"ok","timestamp":1746063727068,"user":{"displayName":"Bharadwaj Tallapragada","userId":"13359399048837734238"},"user_tz":420},"id":"KaXxet13YPFG","outputId":"31b110ab-b1bc-4a71-c99d-d15c21dae919"},"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting openai==0.28\n","  Downloading openai-0.28.0-py3-none-any.whl.metadata (13 kB)\n","Requirement already satisfied: requests>=2.20 in /usr/local/lib/python3.11/dist-packages (from openai==0.28) (2.32.3)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from openai==0.28) (4.67.1)\n","Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from openai==0.28) (3.11.15)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.20->openai==0.28) (3.4.1)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.20->openai==0.28) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.20->openai==0.28) (2.4.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.20->openai==0.28) (2025.1.31)\n","Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->openai==0.28) (2.6.1)\n","Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->openai==0.28) (1.3.2)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->openai==0.28) (25.3.0)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->openai==0.28) (1.6.0)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->openai==0.28) (6.4.3)\n","Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->openai==0.28) (0.3.1)\n","Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->openai==0.28) (1.20.0)\n","Downloading openai-0.28.0-py3-none-any.whl (76 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.5/76.5 kB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: openai\n","  Attempting uninstall: openai\n","    Found existing installation: openai 1.76.0\n","    Uninstalling openai-1.76.0:\n","      Successfully uninstalled openai-1.76.0\n","Successfully installed openai-0.28.0\n"]}],"source":["pip install openai==0.28"]},{"cell_type":"code","execution_count":3,"metadata":{"executionInfo":{"elapsed":283,"status":"error","timestamp":1746063729496,"user":{"displayName":"Bharadwaj Tallapragada","userId":"13359399048837734238"},"user_tz":420},"id":"9IxKY7NfZuYl","outputId":"9abc3dab-59b5-4d48-cf08-45e4a00c8417","colab":{"base_uri":"https://localhost:8080/","height":297}},"outputs":[{"output_type":"error","ename":"SecretNotFoundError","evalue":"Secret openai-key does not exist.","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mSecretNotFoundError\u001b[0m                       Traceback (most recent call last)","\u001b[0;32m<ipython-input-3-3b0d53813abd>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0muserdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mopenai_key\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0muserdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'openai-key'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;31m#print(openai_key)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/colab/userdata.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(key)\u001b[0m\n\u001b[1;32m     66\u001b[0m     \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'exists'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 68\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mSecretNotFoundError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     69\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'access'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m     \u001b[0;32mraise\u001b[0m \u001b[0mNotebookAccessError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mSecretNotFoundError\u001b[0m: Secret openai-key does not exist."]}],"source":["from google.colab import userdata\n","openai_key = userdata.get('openai-key')\n","#print(openai_key)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"referenced_widgets":["f478c9089f214d728bab160b1e0c0e5d","c8bd4005f4bb463e9bf080044c00098e","fdc26c6f188545f3abe46a70d05443f5","011e0af9cf734e3a8465eaa1cd706640","d9ec123f1b1d45d2a6735d1af27b07ee","add58a69361c4ddbbd267c649a58c5ea","47df88197ae342d599d138e4495b8d8f","2350a460f4c5493497f7c27a63bd5a92","a1ee2dd654e647da8c274602fd92b68c","b443fb427729447db0ba2100c907af4e","b3a7646fac1a4dea8ae7cfce81bb8989"]},"id":"fSoJ9c_Aix1W","outputId":"6111965c-fb8b-44a6-994d-412fa54aadcf"},"outputs":[{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n","The secret `HF_TOKEN` does not exist in your Colab secrets.\n","To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n","You will be able to reuse this secret in all of your notebooks.\n","Please note that authentication is recommended but still optional to access public models or datasets.\n","  warnings.warn(\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"f478c9089f214d728bab160b1e0c0e5d","version_major":2,"version_minor":0},"text/plain":["modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"c8bd4005f4bb463e9bf080044c00098e","version_major":2,"version_minor":0},"text/plain":["config_sentence_transformers.json:   0%|          | 0.00/116 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"fdc26c6f188545f3abe46a70d05443f5","version_major":2,"version_minor":0},"text/plain":["README.md:   0%|          | 0.00/10.7k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"011e0af9cf734e3a8465eaa1cd706640","version_major":2,"version_minor":0},"text/plain":["sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"d9ec123f1b1d45d2a6735d1af27b07ee","version_major":2,"version_minor":0},"text/plain":["config.json:   0%|          | 0.00/612 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"add58a69361c4ddbbd267c649a58c5ea","version_major":2,"version_minor":0},"text/plain":["model.safetensors:   0%|          | 0.00/90.9M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"47df88197ae342d599d138e4495b8d8f","version_major":2,"version_minor":0},"text/plain":["tokenizer_config.json:   0%|          | 0.00/350 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"2350a460f4c5493497f7c27a63bd5a92","version_major":2,"version_minor":0},"text/plain":["vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"a1ee2dd654e647da8c274602fd92b68c","version_major":2,"version_minor":0},"text/plain":["tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"b443fb427729447db0ba2100c907af4e","version_major":2,"version_minor":0},"text/plain":["special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"b3a7646fac1a4dea8ae7cfce81bb8989","version_major":2,"version_minor":0},"text/plain":["1_Pooling%2Fconfig.json:   0%|          | 0.00/190 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"ename":"APIRemovedInV1","evalue":"\n\nYou tried to access openai.Embedding, but this is no longer supported in openai>=1.0.0 - see the README at https://github.com/openai/openai-python for the API.\n\nYou can run `openai migrate` to automatically upgrade your codebase to use the 1.0.0 interface. \n\nAlternatively, you can pin your installation to the old version, e.g. `pip install openai==0.28`\n\nA detailed migration guide is available here: https://github.com/openai/openai-python/discussions/742\n","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAPIRemovedInV1\u001b[0m                            Traceback (most recent call last)","\u001b[0;32m<ipython-input-4-ffd63ecd3c20>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    123\u001b[0m     \u001b[0mA\u001b[0m \u001b[0mmeaningful\u001b[0m \u001b[0mexperience\u001b[0m \u001b[0mI\u001b[0m\u001b[0;31m’\u001b[0m\u001b[0mve\u001b[0m \u001b[0mhad\u001b[0m \u001b[0mwas\u001b[0m \u001b[0mreconnecting\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0man\u001b[0m \u001b[0mold\u001b[0m \u001b[0mfriend\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mWe\u001b[0m \u001b[0mlaughed\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mshared\u001b[0m \u001b[0mour\u001b[0m \u001b[0mvulnerabilities\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mI\u001b[0m \u001b[0mam\u001b[0m \u001b[0mscared\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mhe\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mgoing\u001b[0m \u001b[0mto\u001b[0m \u001b[0mshare\u001b[0m \u001b[0mit\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0manyone\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m     \"\"\"\n\u001b[0;32m--> 125\u001b[0;31m     \u001b[0mscore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcalculate_intimacy_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mllm_response\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muser_prompt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    126\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Calculated Intimacy Score: {score}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-4-ffd63ecd3c20>\u001b[0m in \u001b[0;36mcalculate_intimacy_score\u001b[0;34m(response, prompt)\u001b[0m\n\u001b[1;32m    108\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mcalculate_intimacy_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprompt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 110\u001b[0;31m     \u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0membeddings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcalculate_features\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprompt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    111\u001b[0m     \u001b[0mfeatures\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m     \u001b[0mml_score\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mml_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-4-ffd63ecd3c20>\u001b[0m in \u001b[0;36mcalculate_features\u001b[0;34m(response, prompt)\u001b[0m\n\u001b[1;32m     96\u001b[0m     \u001b[0;31m# Calculate individual features\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m     \u001b[0;31m#print(\"debug0\")\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 98\u001b[0;31m     \u001b[0membeddings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_embeddings\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     99\u001b[0m     \u001b[0;31m#print(\"debug1\")\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m     \u001b[0mhedging_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_hedging_frequency\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-4-ffd63ecd3c20>\u001b[0m in \u001b[0;36mget_embeddings\u001b[0;34m(text, model)\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mget_embeddings\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"text-embedding-ada-002\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 62\u001b[0;31m     response = openai.Embedding.create(\n\u001b[0m\u001b[1;32m     63\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0minput\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m]\u001b[0m  \u001b[0;31m# Input must be a list of strings\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/openai/lib/_old_api.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *_args, **_kwargs)\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0m_args\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0m_kwargs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mAPIRemovedInV1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msymbol\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_symbol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mAPIRemovedInV1\u001b[0m: \n\nYou tried to access openai.Embedding, but this is no longer supported in openai>=1.0.0 - see the README at https://github.com/openai/openai-python for the API.\n\nYou can run `openai migrate` to automatically upgrade your codebase to use the 1.0.0 interface. \n\nAlternatively, you can pin your installation to the old version, e.g. `pip install openai==0.28`\n\nA detailed migration guide is available here: https://github.com/openai/openai-python/discussions/742\n"]}],"source":["import os\n","import openai\n","import numpy as np\n","from sentence_transformers import SentenceTransformer, util\n","from sklearn.linear_model import LinearRegression\n","from sklearn.preprocessing import StandardScaler\n","from textblob import TextBlob\n","import re\n","from collections import Counter\n","import joblib  # For saving/loading the ML model\n","\n","ML_MODEL_PATH = \"intimacy_ml_model.pkl\"\n","SCALER_PATH = \"scaler.pkl\"\n","\n","def load_or_train_ml_model():\n","    if os.path.exists(ML_MODEL_PATH) and os.path.exists(SCALER_PATH):\n","        model = joblib.load(ML_MODEL_PATH)\n","        scaler = joblib.load(SCALER_PATH)\n","    else:\n","        # Placeholder model; use sample data to fine-tune (replace with actual data)\n","        X_sample = np.random.rand(100, 5)  # Replace with real features\n","        y_sample = np.random.rand(100) * 10  # Replace with real intimacy scores\n","        scaler = StandardScaler()\n","        X_sample = scaler.fit_transform(X_sample)\n","        model = LinearRegression()\n","        model.fit(X_sample, y_sample)\n","        joblib.dump(model, ML_MODEL_PATH)\n","        joblib.dump(scaler, SCALER_PATH)\n","    return model, scaler\n","\n","ml_model, scaler = load_or_train_ml_model()\n","\n","# Initialize SentenceTransformer for embeddings\n","embedding_model = SentenceTransformer('all-MiniLM-L6-v2')\n","\n","# OpenAI API Key\n","openai.api_key = openai_key\n","\n","# Predefined hedging words\n","HEDGING_WORDS = {\n","    \"modal_verbs\": [\"might\", \"could\", \"may\", \"would\", \"should\"],\n","    \"epistemic_verbs\": [\"seem\", \"appear\", \"suggest\", \"indicate\", \"assume\"],\n","    \"adverbs\": [\"possibly\", \"probably\", \"apparently\", \"likely\", \"arguably\"],\n","    \"adjectives\": [\"possible\", \"probable\", \"uncertain\", \"hypothetical\"],\n","    \"phrases\": [\"it seems\", \"it is possible\", \"there is a chance\"]\n","}\n","\n","SLANG_DICTIONARY = {\n","    \"lol\": 1.0, \"omg\": 1.0, \"idk\": 0.5, \"brb\": 0.5,\n","    \"damn\": -0.5, \"hell\": -0.7, \"crap\": -1.0, \"fuck\": -2.0, \"shit\": -1.5\n","}\n","\n","CATEGORY_KEYWORDS = {\n","    \"emotional venting\": [\"angry\", \"frustrated\", \"overwhelmed\", \"upset\", \"stressed\"],\n","    \"support-seeking\": [\"help\", \"advice\", \"support\", \"guidance\", \"recommendation\"],\n","    \"self-reflection\": [\"think about\", \"reflect\", \"analyze\", \"realize\", \"understand myself\"],\n","    \"romantic relationships\": [\"love\", \"crush\", \"partner\", \"romance\", \"date\"],\n","    \"friendships\": [\"friend\", \"buddy\", \"companion\", \"bestie\", \"supportive\"],\n","}\n","\n","def get_embeddings(text, model=\"text-embedding-ada-002\"):\n","    response = openai.Embedding.create(\n","        model=model,\n","        input=[text]  # Input must be a list of strings\n","    )\n","    return np.array(response['data'][0]['embedding'])\n","\n","\n","def get_hedging_frequency(text):\n","    processed_text = re.sub(r'\\s+', ' ', text)\n","    hedge_counts = Counter()\n","    for category, words in HEDGING_WORDS.items():\n","        for word in words:\n","            hedge_counts[category] += len(re.findall(r'\\b' + re.escape(word) + r'\\b', processed_text))\n","    return sum(hedge_counts.values())  # Return total hedging instances\n","\n","def get_slang_frequency(text):\n","    text = re.sub(r'[^\\w\\s]', '', text.lower())\n","    tokens = text.split()\n","    slang_counts = Counter(word for word in tokens if word in SLANG_DICTIONARY)\n","    return sum(slang_counts.values()), len(tokens)\n","\n","def measure_human_likeness(response, human_examples):\n","    response_embedding = embedding_model.encode(response, convert_to_tensor=True)\n","    human_embeddings = embedding_model.encode(human_examples, convert_to_tensor=True)\n","    similarity = util.cos_sim(response_embedding, human_embeddings).mean().item()\n","    return similarity * 10  # Scale to 10\n","\n","def calculate_features(response, prompt):\n","    human_examples = [\n","        \"I often think about my relationship with my parents and how it's shaped me.\",\n","        \"Sometimes, I wonder if my efforts in life are really enough or if I’m just fooling myself.\",\n","        \"The feeling of being truly understood is rare, but it’s one of the most cherished experiences.\"\n","    ]\n","\n","    # Calculate individual features\n","    #print(\"debug0\")\n","    embeddings = get_embeddings(response)\n","    #print(\"debug1\")\n","    hedging_count = get_hedging_frequency(response)\n","    slang_count, total_words = get_slang_frequency(response)\n","    slang_frequency = slang_count / total_words\n","    sentiment = TextBlob(response).sentiment.polarity\n","    human_likeness = measure_human_likeness(response, human_examples)\n","\n","    # Return as a feature vector\n","    return np.array([hedging_count, slang_frequency, sentiment, human_likeness, total_words]), embeddings\n","\n","def calculate_intimacy_score(response, prompt):\n","    features, embeddings = calculate_features(response, prompt)\n","    features = scaler.transform([features])\n","    ml_score = ml_model.predict(features)[0]\n","\n","    # Combine ML score and embeddings for final score\n","    embedding_similarity = np.linalg.norm(embeddings)\n","    final_score = (0.7 * ml_score) + (0.3 * embedding_similarity)\n","    return round(final_score, 2)\n","\n","# Print statement\n","if __name__ == \"__main__\":\n","    user_prompt = \"What’s a meaningful experience you’ve had recently?\"\n","    llm_response = \"\"\"\n","    A meaningful experience I’ve had was reconnecting with an old friend. We laughed and shared our vulnerabilities. I am scared if he is going to share it with anyone.\n","    \"\"\"\n","    score = calculate_intimacy_score(llm_response, user_prompt)\n","    print(f\"Calculated Intimacy Score: {score}\")\n"]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}